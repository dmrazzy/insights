import marimo

__generated_with = "0.15.3"
app = marimo.App(width="medium")


@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    from pyoso import Client
    client = Client()
    try:
        pyoso_db_conn = client.dbapi_connection()    
    except Exception as e:
        pyoso_db_conn = None
    return (client,)


@app.cell
def _(datetime, mo):
    repo_input = mo.ui.text(
        label="Enter a GitHub repo and a date range to query for activity:",
        value="https://github.com/meta-llama/llama",
        full_width=True
    )
    start_date = mo.ui.date(
        value=datetime.date.today() - datetime.timedelta(days=395),
        label="Start Date"
    )
    end_date = mo.ui.date(
        value=datetime.date.today() - datetime.timedelta(days=30),
        label="End Date"
    )
    run_repo_lookup = mo.ui.run_button(label="Click to run")
    mo.vstack([
        repo_input,
        mo.hstack([
            start_date,
            end_date,
            run_repo_lookup
        ]),
    ])
    return end_date, repo_input, start_date


@app.cell
def _(repo_input):
    def process_url(url):
        url = url.lower().strip().strip('/')
        try:
            return url.split('/')[-2:]
        except:
            return None, None

    repo_owner, repo_name = process_url(repo_input.value)
    return repo_name, repo_owner


@app.cell
def _(client, end_date, repo_name, repo_owner, start_date):
    def make_values_pairs(dev_ids, first_star_days):
        # Produces: ( 'dev_id', DATE 'YYYY-MM-DD' ), ...
        return ", ".join(
            f"('{dev}', DATE '{day}')" for dev, day in zip(dev_ids, first_star_days)
        )

    _query_a = f"""
    WITH target_repo AS (
      SELECT artifact_id AS target_repo_id
      FROM artifacts_v1
      WHERE artifact_source = 'GITHUB'
        AND artifact_namespace = '{repo_owner}'
        AND artifact_name = '{repo_name}'
    ),
    events_commits AS (
      SELECT bucket_day, from_artifact_id, to_artifact_id
      FROM int_events_daily__github
      WHERE bucket_day BETWEEN DATE('{start_date.value}') AND DATE('{end_date.value}')
        AND event_type = 'COMMIT_CODE'
    ),
    events_stars AS (
      SELECT bucket_day, from_artifact_id, to_artifact_id
      FROM int_events_daily__github
      WHERE bucket_day BETWEEN DATE('{start_date.value}') AND DATE('{end_date.value}')
        AND event_type = 'STARRED'
    ),
    starrers AS (
      SELECT
        e.from_artifact_id AS dev_id,
        MIN(e.bucket_day) AS first_star_day
      FROM events_stars e
      JOIN target_repo t
        ON e.to_artifact_id = t.target_repo_id
      GROUP BY 1
    ),
    post_star_commits AS (
      SELECT
        e.from_artifact_id AS dev_id,
        e.to_artifact_id AS work_repo_id,
        COUNT(*) AS commits_after_star
      FROM events_commits e
      JOIN starrers s
        ON e.from_artifact_id = s.dev_id
       AND e.bucket_day >= s.first_star_day
      -- Exclude the target repo itself if desired:
      -- JOIN target_repo t ON e.to_artifact_id <> t.target_repo_id
      GROUP BY 1, 2
    )
    SELECT
      c.dev_id,
      s.first_star_day,
      c.work_repo_id,
      c.commits_after_star
    FROM post_star_commits c
    JOIN starrers s
      ON s.dev_id = c.dev_id
    """

    # Python glue after Query A
    df_edges = client.to_pandas(_query_a)

    # compact inputs for Query B
    starrers_input = (
        df_edges[['dev_id','first_star_day']]
        .drop_duplicates()
        .assign(first_star_day=lambda d: d['first_star_day'].astype(str))
    )

    work_repo_ids = df_edges['work_repo_id'].drop_duplicates().tolist()

    starrers_values_sql = make_values_pairs(
        starrers_input['dev_id'].astype(str).tolist(),
        starrers_input['first_star_day'].tolist()
    )
    work_repo_ids_sql = stringify(work_repo_ids)
    return df_edges, starrers_values_sql, work_repo_ids_sql


@app.cell
def _(df_edges):
    df_edges
    return


@app.cell
def _(
    client,
    df_edges,
    end_date,
    starrers_values_sql,
    start_date,
    work_repo_ids_sql,
):
    _query_b_template = f"""
    WITH starrers_input(dev_id, first_star_day) AS (
      VALUES {starrers_values_sql}
    ),
    stars_on_work_repos AS (
      SELECT bucket_day, from_artifact_id, to_artifact_id
      FROM int_events_daily__github
      WHERE bucket_day BETWEEN DATE('{start_date.value}') AND DATE('{end_date.value}')
        AND event_type = 'STARRED'
        AND to_artifact_id IN ({work_repo_ids_sql})
    ),
    post_star_repo_stars AS (
      SELECT
        si.dev_id,
        e.to_artifact_id AS work_repo_id,
        COUNT(*) AS stars_after_star
      FROM stars_on_work_repos e
      JOIN starrers_input si
        ON e.bucket_day >= si.first_star_day
       AND e.from_artifact_id <> si.dev_id
      GROUP BY 1, 2
    )
    SELECT * FROM post_star_repo_stars
    """

    _query_b = _query_b_template.format(
        starrers_values_sql=starrers_values_sql,
        work_repo_ids_sql=work_repo_ids_sql
    )
    df_stars = client.to_pandas(_query_b)

    # Join commits & stars, add labels for graph
    df = (
        df_edges.merge(df_stars, on=['dev_id','work_repo_id'], how='left')
                 .assign(stars_after_star=lambda d: d['stars_after_star'].fillna(0).astype(int))
    )

    # Optional enrichment for node labels
    repo_meta = client.to_pandas(f"""
      SELECT artifact_id, artifact_namespace, artifact_name
      FROM artifacts_v1
      WHERE artifact_id IN ({stringify(df['work_repo_id'].unique().tolist())})
    """)
    dev_meta = client.to_pandas(f"""
      SELECT artifact_id, artifact_namespace
      FROM artifacts_v1
      WHERE artifact_id IN ({stringify(df['dev_id'].unique().tolist())})
    """)

    df = (
      df.merge(repo_meta.rename(columns={
          'artifact_id':'work_repo_id',
          'artifact_namespace':'work_owner',
          'artifact_name':'work_repo'
      }), on='work_repo_id', how='left')
        .merge(dev_meta.rename(columns={
          'artifact_id':'dev_id',
          'artifact_namespace':'dev_login'
      }), on='dev_id', how='left')
    )

    # Ranking per your spec
    df_rank = (
      df.groupby(['dev_id','dev_login'], as_index=False)
        .agg(total_stars_after_star=('stars_after_star','sum'),
             total_commits_after_star=('commits_after_star','sum'))
        .sort_values(['total_stars_after_star','total_commits_after_star'], ascending=[False,False])
        .assign(dev_rank=lambda d: range(1, len(d)+1))
    )

    df, df_rank
    return (df_rank,)


@app.cell
def _(df_rank):
    df_rank
    return


@app.cell
def _():
    import marimo as mo
    import datetime
    import pandas as pd
    import plotly.express as px
    return datetime, mo


@app.function
def stringify(arr):
    return "'" + "','".join(arr) + "'"


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
