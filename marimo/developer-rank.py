import marimo

__generated_with = "0.15.3"
app = marimo.App(width="medium")


@app.cell
def setup_pyoso():
    # This code sets up pyoso to be used as a database provider for this notebook
    # This code is autogenerated. Modification could lead to unexpected results :)
    import marimo as mo
    from pyoso import Client
    client = Client()
    try:
        pyoso_db_conn = client.dbapi_connection()    
    except Exception as e:
        pyoso_db_conn = None
    return client, mo


@app.cell
def about_app(mo):
    mo.vstack([
        mo.md("""
        # Developer Rank Analysis
        <small>Author: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">OSO Team</span> · Last Updated: <span style="background-color: #f0f0f0; padding: 2px 4px; border-radius: 3px;">2025-09-19</span></small>
        """),
        mo.md("""
        This app creates a basic "developer rank" using stars and commits, applied to the network of developers who are interested in a given repository. Note: Longer time periods and very popular repos could take several minutes to execute.
        """),
        mo.accordion({
            "<b>Click to see details on how app was made</b>": mo.accordion({
                "Methodology": """
                - Identifies developers who starred the target repository within the specified date range
                - Tracks their subsequent commits to repositories they work on after their first star
                - Counts stars received by those repositories from the broader ecosystem
                - Ranks developers by total stars received by their work repos and commits made
                - Includes safety limits to handle large datasets efficiently
                """,
                "Data Sources": """
                - [GitHub Events via OSO](https://opensource.observer/)
                - Commit events and star events from the GitHub ecosystem
                - Repository metadata and developer information
                """,
                "Further Resources": """
                - [Getting Started with Pyoso](https://docs.opensource.observer/docs/get-started/python)
                - [Using the Semantic Layer](https://docs.opensource.observer/docs/get-started/using-semantic-layer)
                - [Marimo Documentation](https://docs.marimo.io/)
                """
            })
        })    
    ])
    return


@app.cell
def import_libraries():
    import datetime
    import pandas as pd
    import plotly.express as px
    import plotly.graph_objects as go
    return datetime, pd, px


@app.cell
def configuration_settings(mo):
    repo_input = mo.ui.text(
        label="Enter a GitHub repo URL:",
        value="https://github.com/meta-llama/llama",
        full_width=True
    )
    years_back_input = mo.ui.number(
        label="Years back",
        value=1,
        start=1,
        stop=10,
        step=1,
        full_width=True
    )
    fetch_repo_stars = mo.ui.run_button(label="Fetch Stargazer History")
    mo.vstack([
        mo.md("### Step 1. Select a repo to analyze"),
        mo.hstack([repo_input, years_back_input], widths=[3,1]),
        fetch_repo_stars
    ])
    return fetch_repo_stars, repo_input, years_back_input


@app.cell
def _(datetime, years_back_input):
    lookback_date = (datetime.date.today() - datetime.timedelta(days=365*years_back_input.value))
    lookback_date_str = lookback_date.strftime('%Y-%m-%d')
    return lookback_date, lookback_date_str


@app.cell
def _(mo, repo_input):
    def process_url(url):
        url = url.lower().strip().strip('/')
        try:
            org, repo = url.split('/')[-2:]
            if not len(org) or not len(repo):
                return None, None
            if '.' in org or '.' in repo:
                return None, None
            return org, repo
        except:
            return None, None

    valid_repo = True
    valid_repo_explanation = ""

    repo_owner, repo_name = process_url(repo_input.value)
    if not repo_input.value.startswith("https://github.com/"):
        valid_repo = False
        valid_repo_explanation += f"⛔️ Invalid GitHub URL: {repo_input.value}.<br>"
    else:    
        if not repo_owner or not repo_name:
            valid_repo = False
            valid_repo_explanation += f"⛔️ Unable to parse repository owner and name from the URL: {repo_input.value}<br>."

    mo.md(valid_repo_explanation)
    return repo_name, repo_owner


@app.cell
def _(
    client,
    fetch_repo_stars,
    lookback_date_str,
    mo,
    pd,
    repo_name,
    repo_owner,
):
    mo.stop(not fetch_repo_stars.value)

    _query_repo = f"""
    SELECT artifact_id
    FROM artifacts_v1
    WHERE
      artifact_source = 'GITHUB'
      AND artifact_namespace = '{repo_owner}'
      AND artifact_name = '{repo_name}'
    """

    _df_repo = client.to_pandas(_query_repo)
    repo_id = _df_repo['artifact_id'].iloc[0]

    _query_stars = f"""
    SELECT
      from_artifact_id AS dev_id,
      MIN(bucket_day) AS sample_date
    FROM int_events_daily__github
    WHERE
      to_artifact_id = '{repo_id}'
      AND event_type = 'STARRED'
      AND bucket_day >= DATE('{lookback_date_str}')
    GROUP BY 1
    ORDER BY 2
    """

    df_stargazers = client.to_pandas(_query_stars)
    df_stargazers['sample_date'] = pd.to_datetime(df_stargazers['sample_date'])
    df_stargazers['amount'] = 1
    df_stargazers['cum_amount'] = df_stargazers['amount'].cumsum()
    return df_stargazers, repo_id


@app.cell
def _(datetime, df_stargazers, lookback_date, mo):
    mo.stop(not len(df_stargazers))

    start_date = mo.ui.date(
        value=lookback_date,
        label="Start Date"
    )
    end_date = mo.ui.date(
        value=lookback_date + datetime.timedelta(days=30),
        label="End Date"
    )
    max_developers = mo.ui.number(
        start=50,
        stop=300,
        step=50,
        value=100,
        label="Max Developers to Analyze"
    )
    run_analysis = mo.ui.run_button(label="Fetch Stargazer Network")
    mo.vstack([
        mo.md("### 2. Configure analysis parameters"),
        mo.hstack([
            start_date,
            end_date,
            max_developers
        ]),
        run_analysis
    ])
    return end_date, max_developers, run_analysis, start_date


@app.cell
def _(df_stargazers, end_date, mo, pd, px, start_date):
    df_stargazers_filtered = df_stargazers[(df_stargazers['sample_date'] >= pd.to_datetime(start_date.value)) & (df_stargazers['sample_date'] <= pd.to_datetime(end_date.value))]

    total_stars_all_time = df_stargazers['amount'].sum()
    total_stars_period = df_stargazers_filtered['amount'].sum()

    total_stars_all_time_stat = mo.stat(
        label="Total Stars (All Time)",
        value=str(total_stars_all_time),
    )

    total_stars_period_stat = mo.stat(
        label="Total Stars (Selected Period)",
        value=str(total_stars_period),
    )


    _fig = px.line(
        df_stargazers,
        x="sample_date",
        y="cum_amount",
        title="Stars Over Time",
    )

    _fig.add_vline(x=start_date.value, line_width=3, line_dash="dash", line_color="green")
    _fig.add_vline(x=end_date.value, line_width=3, line_dash="dash", line_color="red")

    mo.vstack([
        mo.hstack([total_stars_all_time_stat, total_stars_period_stat]),    
        mo.ui.plotly(_fig)
    ])
    return


@app.function
def stringify(arr):
    return "'" + "','".join(arr) + "'"


@app.cell
def get_data(end_date, mo, start_date):
    def validate_date_range(start_date, end_date):
        days_diff = (end_date - start_date).days
        if days_diff > 730:
            return False, "⛔️ Date range too large (max 2 years)<br>"
        if days_diff < 7:
            return False, "⛔️ Date range too small (min 1 week)<br>"
        return True, ""

    valid_inputs = True
    valid_inputs_explanation = ""

    if start_date.value >= end_date.value:
        valid_inputs = False
        valid_inputs_explanation += "⛔️ Start date must be before end date.<br>"

    valid_date_range, date_range_explanation = validate_date_range(start_date.value, end_date.value)
    if not valid_date_range:
        valid_inputs = False
        valid_inputs_explanation += date_range_explanation + "\n"

    mo.md(valid_inputs_explanation)
    return (valid_inputs,)


@app.cell
def _(client, end_date, mo, repo_id, run_analysis, start_date, valid_inputs):
    mo.stop(not valid_inputs or not run_analysis.value)

    _query_edges = f"""
    WITH events_stars AS (
      SELECT
        bucket_day,
        from_artifact_id,
        to_artifact_id
      FROM int_events_daily__github
      WHERE
        bucket_day BETWEEN DATE('{start_date.value}') AND DATE('{end_date.value}')
        AND event_type = 'STARRED'
        AND to_artifact_id = '{repo_id}'
    ),
    starrers AS (
      SELECT
        from_artifact_id AS dev_id,
        MIN(bucket_day) AS first_star_day
      FROM events_stars
      GROUP BY 1
    ),
    events_commits AS (
      SELECT
        e.bucket_day,
        s.dev_id,
        e.to_artifact_id AS work_repo_id,
        e.amount
      FROM int_events_daily__github e
      JOIN starrers s
        ON e.from_artifact_id = s.dev_id
      WHERE e.bucket_day >= s.first_star_day
        AND e.event_type = 'COMMIT_CODE'
    ),
    post_star_commits AS (
      SELECT
        dev_id,
        work_repo_id,
        MIN(bucket_day) AS first_commit_day,
        COUNT(DISTINCT bucket_day) AS days_with_commits,
        SUM(amount) AS commits_after_star
      FROM events_commits
      GROUP BY 1, 2
    )
    SELECT
      c.dev_id,
      a.artifact_namespace AS git_user,
      c.work_repo_id,
      c.first_commit_day,
      c.days_with_commits,
      c.commits_after_star
    FROM post_star_commits c
    JOIN artifacts_v1 a  
      ON c.dev_id = a.artifact_id
    ORDER BY c.commits_after_star DESC
    """

    df_edges = client.to_pandas(_query_edges)
    return (df_edges,)


@app.cell
def process_data(client, df_edges, max_developers):
    _dev_list = df_edges.groupby('dev_id')['commits_after_star'].sum().sort_values().tail(max_developers.value).index.to_list()
    _devs_input = df_edges[df_edges['dev_id'].isin(_dev_list)][['dev_id', 'work_repo_id', 'first_commit_day']].drop_duplicates()

    def _make_values_pairs(dev_ids, work_repo_ids, first_days):
        return ", ".join(
            f"('{dev}', '{repo}', DATE '{day}')"
            for dev, repo, day in zip(dev_ids, work_repo_ids, first_days)
        )
    _dev_values_sql = _make_values_pairs(
        _devs_input['dev_id'].tolist(),
        _devs_input['work_repo_id'].tolist(),
        _devs_input['first_commit_day'].tolist()
    )
    _dev_values_sql

    _query_stars = f"""
    WITH devs_input(dev_id, work_repo_id, first_commit_day) AS (
      VALUES {_dev_values_sql}
    )
    SELECT
      di.dev_id AS dev_id,
      e.to_artifact_id AS work_repo_id,
      COUNT(*) AS stars_received
    FROM int_events_daily__github e
    JOIN devs_input di
      ON e.to_artifact_id = di.work_repo_id
    WHERE
      e.bucket_day >= DATE(di.first_commit_day)
      AND e.event_type = 'STARRED'
      AND e.from_artifact_id <> di.dev_id
    GROUP BY 1,2
    """

    df_stars = client.to_pandas(_query_stars)
    df_merged = (
        df_edges.merge(df_stars, on=['dev_id', 'work_repo_id'], how='left')
                .assign(stars_received=lambda d: d['stars_received'].fillna(0).astype(int))
    )

    df_rank = (
      df_merged.groupby(['dev_id','git_user'], as_index=False)
        .agg(
            total_stars_received_by_work_repos=('stars_received','sum'),
            total_commits_after_star=('commits_after_star','sum'),
            unique_repos_worked_on=('work_repo_id','nunique')
        )
        .sort_values(['total_stars_received_by_work_repos','total_commits_after_star'], ascending=[False,False])
        .assign(dev_rank=lambda d: range(1, len(d)+1))
    )
    return (df_rank,)


@app.cell
def generate_stats(df_rank, mo):
    total_developers = mo.stat(
        label="Total Developers",
        bordered=True,
        value=f"{len(df_rank):,.0f}",
    )

    total_stars = mo.stat(
        label="Total Stars Received by Work Repos",
        bordered=True,
        value=f"{df_rank['total_stars_received_by_work_repos'].sum():,.0f}",
    )

    total_commits = mo.stat(
        label="Total Commits",
        bordered=True,
        value=f"{df_rank['total_commits_after_star'].sum():,.0f}",
    )

    unique_repos = mo.stat(
        label="Unique Repos Worked On",
        bordered=True,
        value=f"{df_rank['unique_repos_worked_on'].sum():,.0f}",
    )

    mo.hstack([total_developers, total_stars, total_commits, unique_repos], widths="equal", gap=1)
    return


@app.cell
def generate_plot(df_rank, max_developers, mo, px):
    def make_rect_plot(dataframe, title="", top_n=50, equal_area=False):

        plot_df = (
            dataframe
            .head(top_n)
            .assign(
                combined_score=lambda d: d["total_stars_received_by_work_repos"]*2 + d["total_commits_after_star"]
            )
            .copy()
        )

        value_col = "tile_value"
        plot_df[value_col] = 1 if equal_area else plot_df["combined_score"]

        plot_df["share"] = plot_df[value_col] / plot_df[value_col].sum()

        fig = px.treemap(
            plot_df,
            path=[px.Constant("All"), "git_user"],
            values=value_col,
            color="combined_score",
            color_continuous_scale='Greens',
            hover_data={
                "git_user": True,
                "dev_rank": True,
                "combined_score": True
            },
            title=f"<b>{title}</b>",
        )

        fig.update_traces(
            pathbar=dict(visible=False),
            root_color="white",
            textfont=dict(size=12),
            marker=dict(line=dict(width=0.5, color="#222")),
            hovertemplate="<b>%{customdata[0]}</b><br>Dev Rank: %{customdata[1]}<br>Combined Score: %{customdata[2]}<extra></extra>"
        )

        fig.update_layout(
            paper_bgcolor="white",
            plot_bgcolor="white",
            font=dict(size=12, color="#111"),
            title=dict(text=title, x=0, xanchor="left"),
            margin=dict(t=0, l=20, r=20, b=20),
            coloraxis_showscale=False
        )
        return fig

    _fig = make_rect_plot(df_rank, top_n=50, equal_area=False)

    mo.vstack([
        mo.md(f"### Top {max_developers.value} Developers"),
        mo.ui.plotly(_fig)
    ])
    return


@app.cell
def generate_table(df_rank, mo):
    display_df = (
        df_rank
        .assign(
            total_stars_received_by_work_repos=lambda d: d['total_stars_received_by_work_repos'].astype(int),
            total_commits_after_star=lambda d: d['total_commits_after_star'].astype(int),
            unique_repos_worked_on=lambda d: d['unique_repos_worked_on'].astype(int)
        )
        .rename(columns={
            'dev_rank': 'Rank',
            'git_user': 'Developer',
            'total_stars_received_by_work_repos': 'Stars Received by Work Repos',
            'total_commits_after_star': 'Commits Made',
            'unique_repos_worked_on': 'Repos Worked On'
        })
        .drop(columns=['dev_id'])
    )

    mo.vstack([
        mo.md("### Full Leaderboard"),
        mo.ui.table(
            display_df.reset_index(drop=True),
            selection=None,
            show_column_summaries=False,
            show_data_types=False,
            page_size=25
        )
    ])
    return


@app.cell
def _():
    return


if __name__ == "__main__":
    app.run()
